# Text Vectorization and Similarity Metrics

A comprehensive implementation of text vectorization techniques using Bag-of-Words (BoW) and TF-IDF, along with similarity metrics.

## üìÇ Repository Structure

Week-2/
‚îÇ
‚îú‚îÄ‚îÄ Data/
‚îÇ   ‚îî‚îÄ‚îÄ bbc-news-data.csv             # BBC News Dataset
‚îú‚îÄ‚îÄ bag_of_words.py                   # BoW implementation
‚îú‚îÄ‚îÄ tf_idf.py                         # TF-IDF implementation
‚îú‚îÄ‚îÄ similarity_matrix.py              # Similarity implementation
‚îú‚îÄ‚îÄ preprocessing_bow_tfidf.py        # Preprocessing for vectorization
‚îî‚îÄ‚îÄ keywords_extractor.py             # Keyword extraction implementation


## üéØ Mini Project
The [keyword_extractor.py](https://github.com/mayankdubey1996/NLP/blob/main/Week-2/keyword_extractor.py) implements a complete keyword extraction pipeline using TF-IDF. Key features:
- Text preprocessing and vectorization
- TF-IDF based keyword extraction
- Top-K keywords identification
- Results export to CSV

## üìå Weekly Deliverables Summary

| Day | Focus Area | Key Deliverables | Implementation |
|-----|------------|------------------|----------------|
| 1 | Bag-of-Words | ‚Ä¢ BoW understanding<br>‚Ä¢ Vector generation<br>‚Ä¢ Vocabulary creation | [day1.py](https://github.com/mayankdubey1996/NLP/blob/main/Week-2/day1.py) |
| 2 | TF-IDF | ‚Ä¢ TF-IDF implementation<br>‚Ä¢ Word importance scoring<br>‚Ä¢ Vector comparison | [day2.py](https://github.com/mayankdubey1996/NLP/blob/main/Week-2/day2.py) |
| 3 | Preprocessing | ‚Ä¢ Text cleaning<br>‚Ä¢ Tokenization<br>‚Ä¢ Stop words removal | [day3.py](https://github.com/mayankdubey1996/NLP/blob/main/Week-2/day3.py) |
| 4 | Cosine Similarity | ‚Ä¢ Similarity calculation<br>‚Ä¢ Document comparison<br>‚Ä¢ Vector analysis | [day4.py](https://github.com/mayankdubey1996/NLP/blob/main/Week-2/day4.py) |
| 5-7 | Keyword Extractor | ‚Ä¢ Complete pipeline<br>‚Ä¢ Movie plots analysis<br>‚Ä¢ Keyword extraction | [keyword_extractor.py](https://github.com/mayankdubey1996/NLP/blob/main/Week-2/keyword_extractor.py) |

## üõ†Ô∏è Implementation Details

### Core Components:
1. **Bag-of-Words** ([day1.py](https://github.com/mayankdubey1996/NLP/blob/main/Week-2/day1.py))
   - Vocabulary creation
   - Word count vectorization
   - Document vector generation

2. **TF-IDF** ([day2.py](https://github.com/mayankdubey1996/NLP/blob/main/Week-2/day2.py))
   - Term frequency calculation
   - Inverse document frequency
   - Final weight computation

3. **Text Preprocessing** ([day3.py](https://github.com/mayankdubey1996/NLP/blob/main/Week-2/day3.py))
   - Cleaning and normalization
   - Tokenization
   - Stop words removal

4. **Similarity Metrics** ([day4.py](https://github.com/mayankdubey1996/NLP/blob/main/Week-2/day4.py))
   - Cosine similarity implementation
   - Document comparison
   - Similarity score calculation

## üîß Setup

```bash
pip install scikit-learn pandas numpy
```

from keyword_extractor import KeywordExtractor

## üöÄ Usage

# Initialize extractor

``` python
extractor = KeywordExtractor()
```

# Extract keywords from text

```python
keywords = extractor.extract_keywords("your_text_here", top_k=10)
```

## üìä Output
The keyword extractor generates a CSV file containing:

Document ID/Title
Original text
Top K keywords
Keyword importance scores