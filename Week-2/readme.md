# Text Vectorization and Similarity Metrics

A comprehensive implementation of text vectorization techniques using Bag-of-Words (BoW) and TF-IDF, along with similarity metrics.

## ğŸ“‚ Repository Structure

Week-2/
â”‚
â”œâ”€â”€ Data/
â”‚   â””â”€â”€ bbc-news-data.csv         # BBC News Dataset
â”‚
â”œâ”€â”€ bag_of_words.py               # BoW implementation
â”œâ”€â”€ tf_idf.py                     # TF-IDF implementation  
â”œâ”€â”€ similarity_matrix.py          # Similarity implementation
â”œâ”€â”€ preprocessing_bow_tfidf.py    # Preprocessing for vectorization
â”‚
â””â”€â”€ keywords_extractor.py         # Keyword extraction implementation


## ğŸ¯ Mini Project
The [keyword_extractor.py](https://github.com/mayankdubey1996/NLP/blob/main/Week-2/keyword_extractor.py) implements a complete keyword extraction pipeline using TF-IDF. Key features:
- Text preprocessing and vectorization
- TF-IDF based keyword extraction
- Top-K keywords identification
- Results export to CSV

## ğŸ“Œ Weekly Deliverables Summary

| Day | Focus Area | Key Deliverables | Implementation |
|-----|------------|------------------|----------------|
| 1 | Bag-of-Words | â€¢ BoW understanding<br>â€¢ Vector generation<br>â€¢ Vocabulary creation | [day1.py](https://github.com/mayankdubey1996/NLP/blob/main/Week-2/day1.py) |
| 2 | TF-IDF | â€¢ TF-IDF implementation<br>â€¢ Word importance scoring<br>â€¢ Vector comparison | [day2.py](https://github.com/mayankdubey1996/NLP/blob/main/Week-2/day2.py) |
| 3 | Preprocessing | â€¢ Text cleaning<br>â€¢ Tokenization<br>â€¢ Stop words removal | [day3.py](https://github.com/mayankdubey1996/NLP/blob/main/Week-2/day3.py) |
| 4 | Cosine Similarity | â€¢ Similarity calculation<br>â€¢ Document comparison<br>â€¢ Vector analysis | [day4.py](https://github.com/mayankdubey1996/NLP/blob/main/Week-2/day4.py) |
| 5-7 | Keyword Extractor | â€¢ Complete pipeline<br>â€¢ Movie plots analysis<br>â€¢ Keyword extraction | [keyword_extractor.py](https://github.com/mayankdubey1996/NLP/blob/main/Week-2/keyword_extractor.py) |

## ğŸ› ï¸ Implementation Details

### Core Components:
1. **Bag-of-Words** ([day1.py](https://github.com/mayankdubey1996/NLP/blob/main/Week-2/day1.py))
   - Vocabulary creation
   - Word count vectorization
   - Document vector generation

2. **TF-IDF** ([day2.py](https://github.com/mayankdubey1996/NLP/blob/main/Week-2/day2.py))
   - Term frequency calculation
   - Inverse document frequency
   - Final weight computation

3. **Text Preprocessing** ([day3.py](https://github.com/mayankdubey1996/NLP/blob/main/Week-2/day3.py))
   - Cleaning and normalization
   - Tokenization
   - Stop words removal

4. **Similarity Metrics** ([day4.py](https://github.com/mayankdubey1996/NLP/blob/main/Week-2/day4.py))
   - Cosine similarity implementation
   - Document comparison
   - Similarity score calculation

## ğŸ”§ Setup

```bash
pip install scikit-learn pandas numpy
```

from keyword_extractor import KeywordExtractor

## ğŸš€ Usage

# Initialize extractor

``` python
extractor = KeywordExtractor()
```

# Extract keywords from text

```python
keywords = extractor.extract_keywords("your_text_here", top_k=10)
```

## ğŸ“Š Output
The keyword extractor generates a CSV file containing:

Document ID/Title
Original text
Top K keywords
Keyword importance scores